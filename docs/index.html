<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Introduction · Perform semiparametric AUC model in Julia</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Ubuntu+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/highlightjs/default.css" rel="stylesheet" type="text/css"/><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="index.html"><img class="logo" src="assets/logo.png" alt="Perform semiparametric AUC model in Julia logo"/></a><h1>Perform semiparametric AUC model in Julia</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href="index.html">Introduction</a><ul class="internal"><li><a class="toctext" href="#Semi-parametric-Area-Under-the-Curve-(sAUC)-Regression-1">Semi-parametric Area Under the Curve (sAUC) Regression</a></li></ul></li><li><a class="toctext" href="install.html">Installation</a></li><li><a class="toctext" href="paper.html">Article</a></li><li><a class="toctext" href="example-julia.html">Example</a></li><li><a class="toctext" href="command.html">References</a></li><li><a class="toctext" href="code.html">Code</a></li><li><a class="toctext" href="example.html">sAUC in R</a></li><li><a class="toctext" href="r-shiny.html">sAUC in R Shiny</a></li><li><a class="toctext" href="example-python.html">saucpy in Python</a></li><li><a class="toctext" href="bohora.html">Developer</a></li><li><a class="toctext" href="bug-report.html">Report Bugs</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href="index.html">Introduction</a></li></ul><a class="edit-page" href="https://github.com/sbohora/SemiparametricAUC.jl/tree/1cd5f70a45cae798e111d21fbad44eb75f68d736/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/></header><h2><a class="nav-anchor" id="Semi-parametric-Area-Under-the-Curve-(sAUC)-Regression-1" href="#Semi-parametric-Area-Under-the-Curve-(sAUC)-Regression-1">Semi-parametric Area Under the Curve (sAUC) Regression</a></h2><p>Perform AUC analyses with discrete covariates and a semi-parametric estimation</p><h3><a class="nav-anchor" id="What-is-sAUC-model-and-why?-1" href="#What-is-sAUC-model-and-why?-1">What is sAUC model and why?</a></h3><p>In many applications, comparing two groups while adjusting for multiple covariates is desired for the statistical analysis.  For instance, in clinical trials, adjusting for covariates is a necessary aspect of the statistical analysis in order to improve the precision of the treatment comparison and to assess effect modification. sAUC is a semi-parametric AUC regression model to compare the effect of two treatment groups in the intended non-normal outcome while adjusting for discrete covariates. More detailed reasons on what it is and why it is proposed are outlined in <a href="https://sbohora.github.io/sAUC/articles/bohora-etal-sauc-paper.pdf">this paper</a>. A major reason behind the development of this method is that this method is computationally simple and is based on closed-form parameter and standard error estimation.</p><h3><a class="nav-anchor" id="Model-1" href="#Model-1">Model</a></h3><p>We consider applications that compare a response variable y between two groups (A and B) while adjusting for k categorical covariates <span>$X_1,X_2,...,X_k$</span>.  The response variable y is a continuous or ordinal variable that is not normally distributed.  Without loss of generality, we assume each covariate is coded such that <span>$X_i=1,...,n_i$</span>,for <span>$i=1,...,k$</span>. For each combination of the levels of the covariates, we define the Area Under the ROC curve (AUC) in the following way:</p><div>\[\pi_{x_1 x_2...x_k}=P(Y^A&gt;Y^B|X_1=x_1,X_2=x_2,...,X_k=x_k )+\frac{1}{2} P(Y^A=Y^B|X_1=x_1,X_2=x_2,...,X_k=x_k ),\]</div><p>where <span>$x_1=1,...,n_1,...,x_k=1,...,n_k$</span>, and <span>$Y^A$</span> and <span>$Y^B$</span> are two randomly chosen observations from Group A and B, respectively.  The second term in the above equation is for the purpose of accounting ties.</p><p>For each covariate <span>$X_i$</span>, without loss of generality, we use the last category as the reference category and define (<span>$n_i-1$</span>) dummy variables <span>$X_i^{(1)},X_i^{(2)},...,X_i^{(n_i-1)}$</span> such that</p><div>\[X_i^{(j)} (x)= \left\{\begin{array}
{rrr}
1, j = x \\
0, j \ne x,
\end{array}\right.\]</div><p>where <span>$i=1,...,k; j=1,...,n_i-1; x=1,...,n_i$</span>.   </p><p>We model the association between AUC <span>$\pi_{x_1 x_2...x_k}$</span> and covariates using a logistic model.  Such a model specifies that the logit of <span>$\pi_{x_1 x_2...x_k}$</span> is a linear combination of terms that are products of the dummy variables defined above.  Specifically,</p><div>\[logit(\pi_{x_1 x_2...x_k } )=Z_{x_1 x_2...x_k} \boldsymbol{\beta},\]</div><p>where <span>$Z_{x_1 x_2...x_k}$</span> is a row vector whose elements are zeroes or ones and are products of <span>$X_1^{(1)} (x_1 ),...,X_1^{(n_i-1) } (x_1),...,X_k^{(1)} (x_k),...,X_k^{(n_k-1)} (x_k)$</span>, and <span>$\boldsymbol{\beta}$</span> is a column vector of nonrandom unknown parameters.  Now, define a column vector <span>$\pi$</span> by stacking up <span>$\pi_{x_1 x_2...x_k}$</span> and define a matrix Z by stacking up <span>$Z_{x_1 x_2...x_k}$</span>, as <span>$x_i$</span> ranges from 1 to <span>$n_i, i=1,...,k$</span>, our final model is  </p><div>\[logit(\pi)=Z\boldsymbol{\beta} ...(1)\]</div><p>The reason for us to use a logit transformation of the AUC instead of using the original AUC is for variance stabilization.  We will illustrate the above general model using examples.</p><h3><a class="nav-anchor" id="Estimation-1" href="#Estimation-1">Estimation</a></h3><p>First, we denote the number of observations with covariates <span>$X_1=i_1,...,X_k=i_k$</span> in groups A and B by <span>$N_{i_1...i_k}^A$</span> and <span>$N_{i_1...i_k}^B$</span>, respectively.  We assume both <span>$N_{i_1...i_k}^A$</span> and <span>$N_{i_1...i_k}^B$</span> are greater than zero in the following development.  An unbiased estimator of <span>$\pi_{i_1...i_k}$</span> proposed by Mann and Whitney (1947) is</p><div>\[\hat{\pi}_{i_1...i_k}=\frac{\sum_{l=1}^{N_{i_1...i_k}^A} \sum_{j=1}^{N_{i_1...i_k}^B} I_{lj}}{N_{i_1...i_k}^A N_{i_1...i_k}^B},\]</div><p>where</p><div>\[I_{i_1... i_k; lj}= \left\{\begin{array}
{rrr}
1, Y_{i_1...i_k; l}^A&gt;Y_{i_1...i_k; j}^B \\
\frac{1}{2}, Y_{i_1...i_k; l}^A=Y_{i_1...i_k; j}^B \\
0, Y_{i_1...i_k; l}^A&lt;Y_{i_1...i_k; j}^B
\end{array}\right.\]</div><p>and <span>$Y_{i_1...i_k; l}^A$</span> and <span>$Y_{i_1...i_k; j}^B$</span> are observations with <span>$X_1=i_1,...,X_k=i_k$</span> in groups A and B, respectively.  Delong, Delong and Clarke-Pearson (1988) have shown that</p><div>\[\hat{\pi}_{i_1...i_k} \approx N(\pi_{i_1...i_k},\sigma_{i_1...i_k}^2).\]</div><p>In order to obtain an estimator for <span>$\sigma_{i_1...i_k}^2$</span>, they first computed</p><div>\[V_{i_1...i_k; l}^A=\frac{1}{N_{i_1...i_k}^B } \sum_{j=1}^{N_{i_1...i_k}^B} I_{lj},  	l=1,...,N_{i_1...i_k}^A\]</div><p>and</p><div>\[V_{i_1...i_k;j}^B=\frac{1}{N_{i_1...i_k}^A } \sum_{l=1}^{N_{i_1...i_k}^A} I_{lj},  	j=1,...,N_{i_1...i_k}^B\]</div><p>Then, an estimate of the variance of the nonparametric AUC was</p><div>\[\hat{\sigma}_{i_1...i_k}^2=\frac{(s_{i_1...i_k}^A )^2}{N_{i_1...i_k}^A} + \frac{(s_{i_1...i_k}^B )^2}{N_{i_1...i_k}^B},\]</div><p>where</p><div>\[(s_{i_1...i_k}^A )^2\]</div><p>and <span>$(s_{i_1...i_k}^B )^2$</span> were the sample variances of</p><div>\[V_{i_1...i_k; l}^A; l=1,...,N_{i_1...i_k}^A\]</div><p>and <span>$V_{i_1...i_k; j}^B; j=1,...,N_{i_1...i_k}^B,$</span> respectively.  Clearly, we need both <span>$N_{i_1...i_k}^A$</span> and <span>$N_{i_1...i_k}^B$</span> are greater than two in order to compute <span>$\hat{\sigma}_{i_1...i_k}^2$</span>.</p><p>Now, in order to estimate parameters in Model (1), we first derive the asymptotic variance of <span>$\hat{\gamma}_{i_1...i_k}$</span> using the delta method, which results in</p><div>\[\hat{\gamma}_{i_1...i_k}=logit(\hat{\pi}_{i_1...i_k}) \approx N(logit(\pi_{i_1...i_k}),\tau_{i_1...i_k}^2),\]</div><p>where <span>$\hat{\tau}_{i_1...i_k}^2=\frac{\hat{\gamma}_{i_1...i_k}^2}{\hat{\pi}_{i_1...i_k}^2  (1-\hat{\pi}_{i_1...i_k})^2}$</span></p><p>Rewriting the above model, we obtain</p><div>\[\hat{\gamma}_{i_1...i_k}=logit(\pi_{i_1...i_k }) =Z_{i_1...i_k} \boldsymbol{\beta} + \epsilon_{i_1...i_k}\]</div><p>where,</p><div>\[\epsilon_{i_1,...,i_k} \approx N(0,\tau_{i_1,...,i_k}^2)\]</div><p>.  Then, by stacking up the <span>$\hat{\gamma}_{1_i,...,i_k}$</span> to be <span>$\hat{\gamma}, Z_{i_1...i_k}$</span> to be <span>$\boldsymbol{Z}$</span>, and <span>$\epsilon_{i_1,...,i_k}$</span> to be <span>$\boldsymbol{\epsilon}$</span>, we have</p><div>\[\boldsymbol{\hat{\gamma}} =logit \boldsymbol{\hat{\pi}} = \boldsymbol{Z\beta + \epsilon},\]</div><p>where, <span>$E(\epsilon)=0$</span> and <span>$\hat{T}=Var(\epsilon)=diag(\hat{\tau}_{i_1... i_k}^2)$</span> which is a diagonal matrix.  Finally, by using the generalized least squares method, we estimate the parameters <span>$\beta$</span> and its variance-covariance matrix as follows;</p><div>\[\boldsymbol{\hat{\beta} ={(\hat{Z}^T  \hat{T}^{-1}  Z)}^{-1} Z^T  \hat{T}^{-1} \hat{\gamma}}\]</div><p>and</p><p>The above equations can be used to construct a 100(1-<span>$\alpha$</span>)% Wald confidence intervals for <span>$\boldsymbol{\beta_i}$</span> using formula</p><div>\[\hat{\beta}_i \pm Z_{1-\frac{\alpha}{2}} \sqrt{\hat{V}(\hat{\beta}_i)},\]</div><p>where <span>$Z_{1-\frac{\alpha}{2}}$</span> is the <span>$(1-\frac{\alpha}{2})^{th}$</span> quantile of the standard normal distribution.  Equivalently, we reject</p><div>\[H_0:\beta_i = 0\]</div><p>if <span>$|\hat{\beta}_i| &gt; Z_{1-\frac{\alpha}{2}} \sqrt{\hat{V}(\hat{\beta}_i)},$</span></p><p>The p-value for testing <span>$H_0$</span> is <span>$2 * P(Z &gt; |\hat{\beta}_i|/\sqrt{\hat{V}\hat{\beta}_i}),$</span></p><p>where Z is a random variable with the standard normal distribution.</p><p>Now, the total number of cells (combinations of covariates <span>$X_1,...,X_k$</span> is <span>$n_1 n_2...n_k$</span>. As mentioned earlier, for a cell to be usable in the estimation, the cell needs to have at least two observations from Group A and two observations from Group B.  As long as the total number of usable cells is larger than the dimension of <span>$\boldsymbol{\beta}$</span>, then the matrix <span>${\boldsymbol{\hat{Z}^T  \hat{T}^{-1}  Z}}$</span> is invertible and consequently,<span>$\boldsymbol{\hat{\beta}}$</span> is computable and model (1) is identifiable.</p><footer><hr/><a class="next" href="install.html"><span class="direction">Next</span><span class="title">Installation</span></a></footer></article></body></html>
